{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b5396",
   "metadata": {},
   "source": [
    "# Feature Engineering for Football Analytics\n",
    "\n",
    "This notebook focuses on creating position-specific features and advanced metrics for player performance prediction.\n",
    "\n",
    "## Contents\n",
    "1. Position-Specific Feature Creation\n",
    "2. Form Indicators and Rolling Statistics\n",
    "3. Opposition Difficulty Ratings\n",
    "4. Fatigue and Load Management Metrics\n",
    "5. Home Advantage and Context Features\n",
    "6. Feature Selection and Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e045fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99622f2",
   "metadata": {},
   "source": [
    "## 1. Position-Specific Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6e2516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading historical FPL data for feature engineering...\n",
      "✅ Loaded 2960 performance records\n",
      "✅ Loaded 740 player profiles\n",
      "📊 Gameweeks: [np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
      "🎯 Players: 740\n",
      "\n",
      "📋 Performance Data Structure:\n",
      "Columns: ['gameweek', 'player_id', 'web_name', 'element_type', 'team_id', 'total_points', 'goals_scored', 'assists', 'saves', 'clean_sheets', 'minutes', 'now_cost', 'selected_by_percent', 'transfers_in', 'transfers_out', 'bonus', 'yellow_cards', 'red_cards', 'shots', 'shots_on_target', 'key_passes', 'tackles', 'interceptions', 'clearances', 'aerial_duels_won', 'aerial_duels_attempted', 'dribbles_completed', 'dribbles_attempted', 'passes_completed', 'passes_attempted', 'penalties_scored', 'penalties_attempted', 'penalties_saved', 'penalties_faced', 'goals_conceded', 'team', 'form']\n",
      "\n",
      "📋 Sample Records:\n",
      "       web_name  element_type  gameweek  total_points  minutes\n",
      "0          Raya             1         1             5       90\n",
      "1  Arrizabalaga             1         1             0        0\n",
      "2          Hein             1         1             1        0\n",
      "3       Setford             1         1             0        0\n",
      "4       Gabriel             2         1             4       90\n",
      "\n",
      "🔧 Position-specific feature engineering initialized!\n",
      "📊 Ready to process 2960 records across 4 positions\n"
     ]
    }
   ],
   "source": [
    "# Load historical FPL data for feature engineering\n",
    "import sys\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "def load_historical_data():\n",
    "    \"\"\"\n",
    "    Load 2024/25 historical data for 2025/26 season prediction model training\n",
    "    \"\"\"\n",
    "    print(\"🔄 Loading historical FPL data for feature engineering...\")\n",
    "    \n",
    "    db_path = '../../data/fpl_data.db'\n",
    "    \n",
    "    if not Path(db_path).exists():\n",
    "        raise FileNotFoundError(f\"Database not found: {db_path}\")\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Load gameweek performance data\n",
    "    players_df = pd.read_sql_query(\"\"\"\n",
    "        SELECT * FROM player_gameweeks \n",
    "        ORDER BY gameweek, player_id\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    # Load player metadata\n",
    "    players_meta = pd.read_sql_query(\"\"\"\n",
    "        SELECT * FROM players_current\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"✅ Loaded {len(players_df)} performance records\")\n",
    "    print(f\"✅ Loaded {len(players_meta)} player profiles\")\n",
    "    print(f\"📊 Gameweeks: {sorted(players_df['gameweek'].unique())}\")\n",
    "    print(f\"🎯 Players: {players_df['player_id'].nunique()}\")\n",
    "    \n",
    "    return players_df, players_meta\n",
    "\n",
    "# Load the data\n",
    "players_df, players_meta = load_historical_data()\n",
    "\n",
    "# Show basic data structure\n",
    "print(f\"\\n📋 Performance Data Structure:\")\n",
    "print(f\"Columns: {list(players_df.columns)}\")\n",
    "print(f\"\\n📋 Sample Records:\")\n",
    "print(players_df[['web_name', 'element_type', 'gameweek', 'total_points', 'minutes']].head())\n",
    "\n",
    "class PositionFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Create position-specific features for football players using real FPL data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.position_mapping = {1: 'GKP', 2: 'DEF', 3: 'MID', 4: 'FWD'}\n",
    "        \n",
    "        # Position-specific feature weights and importance\n",
    "        self.position_weights = {\n",
    "            'GKP': {\n",
    "                'saves': 1.0,\n",
    "                'clean_sheets': 1.0,\n",
    "                'goals_conceded': -1.0,\n",
    "                'minutes': 0.8\n",
    "            },\n",
    "            'DEF': {\n",
    "                'tackles': 1.0,\n",
    "                'interceptions': 1.0,\n",
    "                'clearances': 0.9,\n",
    "                'clean_sheets': 0.8,\n",
    "                'goals_scored': 0.7\n",
    "            },\n",
    "            'MID': {\n",
    "                'key_passes': 1.0,\n",
    "                'passes_completed': 0.8,\n",
    "                'assists': 1.0,\n",
    "                'dribbles_completed': 0.7,\n",
    "                'goals_scored': 0.9\n",
    "            },\n",
    "            'FWD': {\n",
    "                'goals_scored': 1.0,\n",
    "                'assists': 0.8,\n",
    "                'shots_on_target': 0.9,\n",
    "                'shots': 0.8,\n",
    "                'minutes': 0.7\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def create_goalkeeper_features(self, df):\n",
    "        \"\"\"\n",
    "        Create goalkeeper-specific features\n",
    "        \"\"\"\n",
    "        print(\"🥅 Engineering goalkeeper features...\")\n",
    "        gk_df = df[df['element_type'] == 1].copy()\n",
    "        \n",
    "        if len(gk_df) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Save percentage (handles division by zero)\n",
    "        gk_df['save_percentage'] = np.where(\n",
    "            (gk_df['saves'] + gk_df['goals_conceded']) > 0,\n",
    "            gk_df['saves'] / (gk_df['saves'] + gk_df['goals_conceded']),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Clean sheet probability based on recent form\n",
    "        gk_df['clean_sheet_rate'] = gk_df.groupby('player_id')['clean_sheets'].transform(\n",
    "            lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Goals conceded per 90 minutes\n",
    "        gk_df['goals_conceded_per_90'] = np.where(\n",
    "            gk_df['minutes'] > 0,\n",
    "            (gk_df['goals_conceded'] * 90) / gk_df['minutes'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Save points efficiency\n",
    "        gk_df['save_efficiency'] = np.where(\n",
    "            gk_df['saves'] > 0,\n",
    "            gk_df['total_points'] / gk_df['saves'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Created features for {len(gk_df)} goalkeeper records\")\n",
    "        return gk_df\n",
    "    \n",
    "    def create_defender_features(self, df):\n",
    "        \"\"\"\n",
    "        Create defender-specific features\n",
    "        \"\"\"\n",
    "        print(\"🛡️ Engineering defender features...\")\n",
    "        def_df = df[df['element_type'] == 2].copy()\n",
    "        \n",
    "        if len(def_df) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Defensive actions per 90 minutes\n",
    "        def_df['defensive_actions_per_90'] = np.where(\n",
    "            def_df['minutes'] > 0,\n",
    "            ((def_df['tackles'] + def_df['interceptions'] + def_df['clearances']) * 90) / def_df['minutes'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Clean sheet contribution\n",
    "        def_df['clean_sheet_rate'] = def_df.groupby('player_id')['clean_sheets'].transform(\n",
    "            lambda x: x.rolling(window=4, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Aerial duel success rate\n",
    "        def_df['aerial_success_rate'] = np.where(\n",
    "            def_df['aerial_duels_attempted'] > 0,\n",
    "            def_df['aerial_duels_won'] / def_df['aerial_duels_attempted'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Attack contribution (goals + assists)\n",
    "        def_df['attacking_returns'] = def_df['goals_scored'] + def_df['assists']\n",
    "        \n",
    "        # Pass completion rate\n",
    "        def_df['pass_completion_rate'] = np.where(\n",
    "            def_df['passes_attempted'] > 0,\n",
    "            def_df['passes_completed'] / def_df['passes_attempted'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Created features for {len(def_df)} defender records\")\n",
    "        return def_df\n",
    "    \n",
    "    def create_midfielder_features(self, df):\n",
    "        \"\"\"\n",
    "        Create midfielder-specific features\n",
    "        \"\"\"\n",
    "        print(\"⚽ Engineering midfielder features...\")\n",
    "        mid_df = df[df['element_type'] == 3].copy()\n",
    "        \n",
    "        if len(mid_df) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Creativity metrics\n",
    "        mid_df['creativity_index'] = (\n",
    "            mid_df['key_passes'] * 2 + \n",
    "            mid_df['assists'] * 3 + \n",
    "            mid_df['dribbles_completed']\n",
    "        )\n",
    "        \n",
    "        # Pass completion and volume\n",
    "        mid_df['pass_completion_rate'] = np.where(\n",
    "            mid_df['passes_attempted'] > 0,\n",
    "            mid_df['passes_completed'] / mid_df['passes_attempted'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        mid_df['passes_per_90'] = np.where(\n",
    "            mid_df['minutes'] > 0,\n",
    "            (mid_df['passes_completed'] * 90) / mid_df['minutes'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Dribble success rate\n",
    "        mid_df['dribble_success_rate'] = np.where(\n",
    "            mid_df['dribbles_attempted'] > 0,\n",
    "            mid_df['dribbles_completed'] / mid_df['dribbles_attempted'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Goal involvement (goals + assists)\n",
    "        mid_df['goal_involvement'] = mid_df['goals_scored'] + mid_df['assists']\n",
    "        \n",
    "        # Shots per 90 (attacking threat)\n",
    "        mid_df['shots_per_90'] = np.where(\n",
    "            mid_df['minutes'] > 0,\n",
    "            (mid_df['shots'] * 90) / mid_df['minutes'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Created features for {len(mid_df)} midfielder records\")\n",
    "        return mid_df\n",
    "    \n",
    "    def create_forward_features(self, df):\n",
    "        \"\"\"\n",
    "        Create forward-specific features\n",
    "        \"\"\"\n",
    "        print(\"⚡ Engineering forward features...\")\n",
    "        fwd_df = df[df['element_type'] == 4].copy()\n",
    "        \n",
    "        if len(fwd_df) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Shot conversion rate\n",
    "        fwd_df['shot_conversion_rate'] = np.where(\n",
    "            fwd_df['shots'] > 0,\n",
    "            fwd_df['goals_scored'] / fwd_df['shots'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Shots on target rate\n",
    "        fwd_df['shots_on_target_rate'] = np.where(\n",
    "            fwd_df['shots'] > 0,\n",
    "            fwd_df['shots_on_target'] / fwd_df['shots'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Goals per 90 minutes\n",
    "        fwd_df['goals_per_90'] = np.where(\n",
    "            fwd_df['minutes'] > 0,\n",
    "            (fwd_df['goals_scored'] * 90) / fwd_df['minutes'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Total attacking returns\n",
    "        fwd_df['attacking_returns'] = fwd_df['goals_scored'] + fwd_df['assists']\n",
    "        \n",
    "        # Minutes per goal (lower is better)\n",
    "        fwd_df['minutes_per_goal'] = np.where(\n",
    "            fwd_df['goals_scored'] > 0,\n",
    "            fwd_df['minutes'] / fwd_df['goals_scored'],\n",
    "            999  # High value for players with no goals\n",
    "        )\n",
    "        \n",
    "        # Expected vs actual (using shots as proxy for xG)\n",
    "        fwd_df['finishing_ability'] = np.where(\n",
    "            fwd_df['shots_on_target'] > 0,\n",
    "            fwd_df['goals_scored'] / fwd_df['shots_on_target'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Created features for {len(fwd_df)} forward records\")\n",
    "        return fwd_df\n",
    "\n",
    "# Initialize the feature engineer\n",
    "feature_engineer = PositionFeatureEngineer()\n",
    "\n",
    "print(f\"\\n🔧 Position-specific feature engineering initialized!\")\n",
    "print(f\"📊 Ready to process {len(players_df)} records across 4 positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62d6e0",
   "metadata": {},
   "source": [
    "## 2. Form Indicators and Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce6a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating position-specific features...\n",
      "🥅 Engineering goalkeeper features...\n",
      "✅ Created features for 344 goalkeeper records\n",
      "🛡️ Engineering defender features...\n",
      "✅ Created features for 980 defender records\n",
      "⚽ Engineering midfielder features...\n",
      "✅ Created features for 1312 midfielder records\n",
      "⚡ Engineering forward features...\n",
      "✅ Created features for 324 forward records\n",
      "\n",
      "📊 Position-specific feature creation complete!\n",
      "✅ Total enhanced records: 2960\n",
      "📋 New features added per position:\n",
      "\n",
      "GKP (344 records):\n",
      "   New features: ['save_percentage', 'clean_sheet_rate', 'goals_conceded_per_90', 'save_efficiency', 'defensive_actions_per_90', 'aerial_success_rate', 'attacking_returns', 'pass_completion_rate', 'creativity_index', 'passes_per_90', 'dribble_success_rate', 'goal_involvement', 'shots_per_90', 'shot_conversion_rate', 'shots_on_target_rate', 'goals_per_90', 'minutes_per_goal', 'finishing_ability']\n",
      "   • save_percentage: 1.000\n",
      "   • clean_sheet_rate: 0.000\n",
      "   • goals_conceded_per_90: 0.000\n",
      "\n",
      "DEF (980 records):\n",
      "   New features: ['save_percentage', 'clean_sheet_rate', 'goals_conceded_per_90', 'save_efficiency', 'defensive_actions_per_90', 'aerial_success_rate', 'attacking_returns', 'pass_completion_rate', 'creativity_index', 'passes_per_90', 'dribble_success_rate', 'goal_involvement', 'shots_per_90', 'shot_conversion_rate', 'shots_on_target_rate', 'goals_per_90', 'minutes_per_goal', 'finishing_ability']\n",
      "   • save_percentage: nan\n",
      "   • clean_sheet_rate: 0.000\n",
      "   • goals_conceded_per_90: nan\n",
      "\n",
      "MID (1312 records):\n",
      "   New features: ['save_percentage', 'clean_sheet_rate', 'goals_conceded_per_90', 'save_efficiency', 'defensive_actions_per_90', 'aerial_success_rate', 'attacking_returns', 'pass_completion_rate', 'creativity_index', 'passes_per_90', 'dribble_success_rate', 'goal_involvement', 'shots_per_90', 'shot_conversion_rate', 'shots_on_target_rate', 'goals_per_90', 'minutes_per_goal', 'finishing_ability']\n",
      "   • save_percentage: nan\n",
      "   • clean_sheet_rate: nan\n",
      "   • goals_conceded_per_90: nan\n",
      "\n",
      "FWD (324 records):\n",
      "   New features: ['save_percentage', 'clean_sheet_rate', 'goals_conceded_per_90', 'save_efficiency', 'defensive_actions_per_90', 'aerial_success_rate', 'attacking_returns', 'pass_completion_rate', 'creativity_index', 'passes_per_90', 'dribble_success_rate', 'goal_involvement', 'shots_per_90', 'shot_conversion_rate', 'shots_on_target_rate', 'goals_per_90', 'minutes_per_goal', 'finishing_ability']\n",
      "   • save_percentage: nan\n",
      "   • clean_sheet_rate: nan\n",
      "   • goals_conceded_per_90: nan\n",
      "\n",
      "✅ Ready for next step: Form and momentum indicators!\n"
     ]
    }
   ],
   "source": [
    "# Create position-specific features for all player types\n",
    "print(\"🔧 Creating position-specific features...\")\n",
    "\n",
    "# Create features for each position\n",
    "gk_features = feature_engineer.create_goalkeeper_features(players_df)\n",
    "def_features = feature_engineer.create_defender_features(players_df)\n",
    "mid_features = feature_engineer.create_midfielder_features(players_df)\n",
    "fwd_features = feature_engineer.create_forward_features(players_df)\n",
    "\n",
    "# Combine all position-specific features\n",
    "enhanced_df = pd.concat([gk_features, def_features, mid_features, fwd_features], ignore_index=True)\n",
    "\n",
    "print(f\"\\n📊 Position-specific feature creation complete!\")\n",
    "print(f\"✅ Total enhanced records: {len(enhanced_df)}\")\n",
    "print(f\"📋 New features added per position:\")\n",
    "\n",
    "# Show sample of new features for each position\n",
    "positions = {1: 'GKP', 2: 'DEF', 3: 'MID', 4: 'FWD'}\n",
    "\n",
    "for pos_code, pos_name in positions.items():\n",
    "    pos_data = enhanced_df[enhanced_df['element_type'] == pos_code]\n",
    "    if len(pos_data) > 0:\n",
    "        # Get columns that aren't in the original dataframe (new features)\n",
    "        original_cols = set(players_df.columns)\n",
    "        new_cols = [col for col in pos_data.columns if col not in original_cols]\n",
    "        \n",
    "        print(f\"\\n{pos_name} ({len(pos_data)} records):\")\n",
    "        print(f\"   New features: {new_cols}\")\n",
    "        \n",
    "        if len(new_cols) > 0:\n",
    "            # Show sample values for the first few new features\n",
    "            sample_player = pos_data.iloc[0]\n",
    "            for col in new_cols[:3]:  # Show first 3 new features\n",
    "                value = sample_player[col]\n",
    "                print(f\"   • {col}: {value:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Ready for next step: Form and momentum indicators!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fefda",
   "metadata": {},
   "source": [
    "## 3. Opposition Difficulty Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27964494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Creating form and momentum indicators...\n",
      "🔄 Calculating rolling statistics...\n",
      "📊 Calculating consistency metrics...\n",
      "🚀 Calculating momentum indicators...\n",
      "💰 Calculating value metrics...\n",
      "\n",
      "✅ Form and momentum features created!\n",
      "📊 Enhanced dataset now has 76 columns\n",
      "\n",
      "📋 Form features created: 16\n",
      "   • form\n",
      "   • points_form_3gw\n",
      "   • goals_form_3gw\n",
      "   • assists_form_3gw\n",
      "   • points_form_4gw\n",
      "   • goals_form_4gw\n",
      "   • assists_form_4gw\n",
      "   • points_form_6gw\n",
      "   • goals_form_6gw\n",
      "   • assists_form_6gw\n",
      "\n",
      "📈 Sample player form progression:\n",
      "Player: Raya (Position: 1)\n",
      "   • 3GW Points Form: 5.00\n",
      "   • Points Momentum: 0.00\n",
      "   • Points Consistency: 0.00\n",
      "   • Form Value: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/kv4_dcgn04d7y6ysgtqt8f7m0000gn/T/ipykernel_3778/4140734383.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  form_df.loc[att_mask, 'attacking_momentum'] = form_df.loc[att_mask].groupby('player_id').apply(\n"
     ]
    }
   ],
   "source": [
    "# Create form and momentum indicators\n",
    "print(\"📈 Creating form and momentum indicators...\")\n",
    "\n",
    "def create_form_features(df):\n",
    "    \"\"\"\n",
    "    Create rolling form and momentum features for FPL players\n",
    "    \"\"\"\n",
    "    form_df = df.copy()\n",
    "    \n",
    "    # Sort by player and gameweek to ensure proper ordering\n",
    "    form_df = form_df.sort_values(['player_id', 'gameweek'])\n",
    "    \n",
    "    print(\"🔄 Calculating rolling statistics...\")\n",
    "    \n",
    "    # Rolling averages for different windows\n",
    "    windows = [3, 4, 6]  # 3, 4, and 6 gameweek windows\n",
    "    \n",
    "    for window in windows:\n",
    "        # Points form\n",
    "        form_df[f'points_form_{window}gw'] = form_df.groupby('player_id')['total_points'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Minutes consistency\n",
    "        form_df[f'minutes_avg_{window}gw'] = form_df.groupby('player_id')['minutes'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Goals form (for attacking players)\n",
    "        form_df[f'goals_form_{window}gw'] = form_df.groupby('player_id')['goals_scored'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "        )\n",
    "        \n",
    "        # Assists form\n",
    "        form_df[f'assists_form_{window}gw'] = form_df.groupby('player_id')['assists'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "        )\n",
    "    \n",
    "    print(\"📊 Calculating consistency metrics...\")\n",
    "    \n",
    "    # Consistency scores (standard deviation - lower is more consistent)\n",
    "    form_df['points_consistency'] = form_df.groupby('player_id')['total_points'].transform(\n",
    "        lambda x: x.rolling(window=4, min_periods=2).std().fillna(0)\n",
    "    )\n",
    "    \n",
    "    form_df['minutes_consistency'] = form_df.groupby('player_id')['minutes'].transform(\n",
    "        lambda x: x.rolling(window=4, min_periods=2).std().fillna(0)\n",
    "    )\n",
    "    \n",
    "    print(\"🚀 Calculating momentum indicators...\")\n",
    "    \n",
    "    # Momentum indicators (trend over recent games)\n",
    "    form_df['points_momentum'] = form_df.groupby('player_id')['total_points'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=2).apply(\n",
    "            lambda y: np.polyfit(range(len(y)), y, 1)[0] if len(y) >= 2 else 0\n",
    "        ).fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Recent vs historical performance\n",
    "    form_df['recent_vs_avg'] = (\n",
    "        form_df['points_form_3gw'] / (form_df.groupby('player_id')['total_points'].transform('mean') + 0.01)\n",
    "    )\n",
    "    \n",
    "    # Clean sheet momentum for defenders and goalkeepers\n",
    "    def_gk_mask = form_df['element_type'].isin([1, 2])\n",
    "    form_df.loc[def_gk_mask, 'clean_sheet_momentum'] = form_df.loc[def_gk_mask].groupby('player_id')['clean_sheets'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).sum()\n",
    "    )\n",
    "    \n",
    "    # Attacking momentum for midfielders and forwards\n",
    "    att_mask = form_df['element_type'].isin([3, 4])\n",
    "    form_df.loc[att_mask, 'attacking_momentum'] = form_df.loc[att_mask].groupby('player_id').apply(\n",
    "        lambda group: (group['goals_scored'] + group['assists']).rolling(window=3, min_periods=1).sum()\n",
    "    ).values\n",
    "    \n",
    "    print(\"💰 Calculating value metrics...\")\n",
    "    \n",
    "    # Value metrics\n",
    "    form_df['points_per_million'] = form_df['total_points'] / form_df['now_cost']\n",
    "    form_df['points_per_minute'] = np.where(\n",
    "        form_df['minutes'] > 0,\n",
    "        form_df['total_points'] / form_df['minutes'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Form-based value\n",
    "    form_df['form_value_3gw'] = form_df['points_form_3gw'] / form_df['now_cost']\n",
    "    \n",
    "    return form_df\n",
    "\n",
    "# Apply form feature engineering\n",
    "enhanced_df = create_form_features(enhanced_df)\n",
    "\n",
    "print(f\"\\n✅ Form and momentum features created!\")\n",
    "print(f\"📊 Enhanced dataset now has {len(enhanced_df.columns)} columns\")\n",
    "\n",
    "# Show sample of new form features\n",
    "form_features = [col for col in enhanced_df.columns if any(keyword in col for keyword in ['form', 'momentum', 'consistency', 'value'])]\n",
    "print(f\"\\n📋 Form features created: {len(form_features)}\")\n",
    "for feature in form_features[:10]:  # Show first 10\n",
    "    print(f\"   • {feature}\")\n",
    "\n",
    "# Quick validation - show a sample player's form progression\n",
    "sample_player = enhanced_df[enhanced_df['minutes'] > 0].iloc[0]\n",
    "print(f\"\\n📈 Sample player form progression:\")\n",
    "print(f\"Player: {sample_player['web_name']} (Position: {sample_player['element_type']})\")\n",
    "print(f\"   • 3GW Points Form: {sample_player['points_form_3gw']:.2f}\")\n",
    "print(f\"   • Points Momentum: {sample_player['points_momentum']:.2f}\")\n",
    "print(f\"   • Points Consistency: {sample_player['points_consistency']:.2f}\")\n",
    "print(f\"   • Form Value: {sample_player['form_value_3gw']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5042ab",
   "metadata": {},
   "source": [
    "## 4. Fatigue and Load Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7368ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Creating advanced efficiency metrics...\n",
      "🎯 Calculating shooting efficiency...\n",
      "🏃 Calculating per-90 minute metrics...\n",
      "🎲 Calculating involvement metrics...\n",
      "📊 Calculating advanced ratios...\n",
      "💎 Calculating quality metrics...\n",
      "🎪 Calculating position-specific efficiency...\n",
      "\n",
      "✅ Advanced efficiency metrics created!\n",
      "📊 Dataset now has 94 total columns\n",
      "\n",
      "📋 Efficiency features created: 27\n",
      "   • clean_sheet_rate\n",
      "   • goals_conceded_per_90\n",
      "   • save_efficiency\n",
      "   • defensive_actions_per_90\n",
      "   • aerial_success_rate\n",
      "   • pass_completion_rate\n",
      "   • passes_per_90\n",
      "   • dribble_success_rate\n",
      "   • goal_involvement\n",
      "   • shots_per_90\n",
      "   • shot_conversion_rate\n",
      "   • shots_on_target_rate\n",
      "\n",
      "📈 Sample efficiency metrics by position:\n",
      "\n",
      "GKP - Raya:\n",
      "   • Price Performance: 0.91\n",
      "   • Minutes per Point: 18.0\n",
      "   • GK Efficiency: 0.60\n",
      "\n",
      "DEF - Gabriel:\n",
      "   • Price Performance: 0.66\n",
      "   • Minutes per Point: 22.5\n",
      "   • DEF Efficiency: 2.50\n",
      "\n",
      "MID - Saka:\n",
      "   • Price Performance: 0.10\n",
      "   • Minutes per Point: 35.0\n",
      "   • MID Efficiency: 9.00\n",
      "\n",
      "FWD - Havertz:\n",
      "   • Price Performance: 0.00\n",
      "   • Minutes per Point: 999.0\n",
      "   • FWD Efficiency: 6.43\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive efficiency and advanced metrics\n",
    "print(\"⚡ Creating advanced efficiency metrics...\")\n",
    "\n",
    "def create_efficiency_metrics(df):\n",
    "    \"\"\"\n",
    "    Create comprehensive efficiency and advanced performance metrics\n",
    "    \"\"\"\n",
    "    eff_df = df.copy()\n",
    "    \n",
    "    print(\"🎯 Calculating shooting efficiency...\")\n",
    "    \n",
    "    # Shooting efficiency (for attacking players)\n",
    "    eff_df['shot_accuracy'] = np.where(\n",
    "        eff_df['shots'] > 0,\n",
    "        eff_df['shots_on_target'] / eff_df['shots'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    eff_df['big_chance_conversion'] = np.where(\n",
    "        eff_df['shots_on_target'] > 0,\n",
    "        eff_df['goals_scored'] / eff_df['shots_on_target'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    print(\"🏃 Calculating per-90 minute metrics...\")\n",
    "    \n",
    "    # Per 90-minute stats (normalized performance)\n",
    "    stats_to_normalize = ['goals_scored', 'assists', 'shots', 'key_passes', 'tackles', 'interceptions']\n",
    "    \n",
    "    for stat in stats_to_normalize:\n",
    "        if stat in eff_df.columns:\n",
    "            eff_df[f'{stat}_per_90'] = np.where(\n",
    "                eff_df['minutes'] > 0,\n",
    "                (eff_df[stat] * 90) / eff_df['minutes'],\n",
    "                0\n",
    "            )\n",
    "    \n",
    "    print(\"🎲 Calculating involvement metrics...\")\n",
    "    \n",
    "    # Team involvement metrics\n",
    "    eff_df['goal_involvement'] = eff_df['goals_scored'] + eff_df['assists']\n",
    "    eff_df['attacking_actions'] = eff_df['shots'] + eff_df['key_passes'] + eff_df['dribbles_completed']\n",
    "    eff_df['defensive_actions'] = eff_df['tackles'] + eff_df['interceptions'] + eff_df['clearances']\n",
    "    \n",
    "    print(\"📊 Calculating advanced ratios...\")\n",
    "    \n",
    "    # Advanced performance ratios\n",
    "    eff_df['pass_accuracy'] = np.where(\n",
    "        eff_df['passes_attempted'] > 0,\n",
    "        eff_df['passes_completed'] / eff_df['passes_attempted'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    eff_df['dribble_success_rate'] = np.where(\n",
    "        eff_df['dribbles_attempted'] > 0,\n",
    "        eff_df['dribbles_completed'] / eff_df['dribbles_attempted'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    eff_df['aerial_win_rate'] = np.where(\n",
    "        eff_df['aerial_duels_attempted'] > 0,\n",
    "        eff_df['aerial_duels_won'] / eff_df['aerial_duels_attempted'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    print(\"💎 Calculating quality metrics...\")\n",
    "    \n",
    "    # Quality indicators\n",
    "    eff_df['minutes_per_point'] = np.where(\n",
    "        eff_df['total_points'] > 0,\n",
    "        eff_df['minutes'] / eff_df['total_points'],\n",
    "        999  # High value for players with no points\n",
    "    )\n",
    "    \n",
    "    # Bonus point efficiency (indicator of impactful performance)\n",
    "    eff_df['bonus_efficiency'] = np.where(\n",
    "        eff_df['minutes'] > 0,\n",
    "        eff_df['bonus'] / (eff_df['minutes'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Price performance ratio\n",
    "    eff_df['price_performance_ratio'] = eff_df['total_points'] / eff_df['now_cost']\n",
    "    \n",
    "    print(\"🎪 Calculating position-specific efficiency...\")\n",
    "    \n",
    "    # Position-specific efficiency metrics\n",
    "    # Goalkeeper efficiency\n",
    "    gk_mask = eff_df['element_type'] == 1\n",
    "    eff_df.loc[gk_mask, 'gk_efficiency'] = np.where(\n",
    "        eff_df.loc[gk_mask, 'minutes'] > 0,\n",
    "        (eff_df.loc[gk_mask, 'saves'] * 0.3 + \n",
    "         eff_df.loc[gk_mask, 'clean_sheets'] * 4 - \n",
    "         eff_df.loc[gk_mask, 'goals_conceded'] * 1) / (eff_df.loc[gk_mask, 'minutes'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Defender efficiency  \n",
    "    def_mask = eff_df['element_type'] == 2\n",
    "    eff_df.loc[def_mask, 'def_efficiency'] = np.where(\n",
    "        eff_df.loc[def_mask, 'minutes'] > 0,\n",
    "        (eff_df.loc[def_mask, 'tackles'] * 0.5 + \n",
    "         eff_df.loc[def_mask, 'interceptions'] * 0.5 + \n",
    "         eff_df.loc[def_mask, 'clearances'] * 0.3 +\n",
    "         eff_df.loc[def_mask, 'clean_sheets'] * 2) / (eff_df.loc[def_mask, 'minutes'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Midfielder efficiency\n",
    "    mid_mask = eff_df['element_type'] == 3\n",
    "    eff_df.loc[mid_mask, 'mid_efficiency'] = np.where(\n",
    "        eff_df.loc[mid_mask, 'minutes'] > 0,\n",
    "        (eff_df.loc[mid_mask, 'key_passes'] * 1.0 + \n",
    "         eff_df.loc[mid_mask, 'assists'] * 3 + \n",
    "         eff_df.loc[mid_mask, 'goals_scored'] * 4 +\n",
    "         eff_df.loc[mid_mask, 'dribbles_completed'] * 0.5) / (eff_df.loc[mid_mask, 'minutes'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Forward efficiency\n",
    "    fwd_mask = eff_df['element_type'] == 4\n",
    "    eff_df.loc[fwd_mask, 'fwd_efficiency'] = np.where(\n",
    "        eff_df.loc[fwd_mask, 'minutes'] > 0,\n",
    "        (eff_df.loc[fwd_mask, 'goals_scored'] * 4 + \n",
    "         eff_df.loc[fwd_mask, 'assists'] * 3 + \n",
    "         eff_df.loc[fwd_mask, 'shots_on_target'] * 0.5) / (eff_df.loc[fwd_mask, 'minutes'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return eff_df\n",
    "\n",
    "# Apply efficiency metrics\n",
    "enhanced_df = create_efficiency_metrics(enhanced_df)\n",
    "\n",
    "print(f\"\\n✅ Advanced efficiency metrics created!\")\n",
    "print(f\"📊 Dataset now has {len(enhanced_df.columns)} total columns\")\n",
    "\n",
    "# Show newly created efficiency features\n",
    "efficiency_features = [col for col in enhanced_df.columns if any(keyword in col for keyword in \n",
    "                      ['efficiency', 'per_90', 'accuracy', 'ratio', 'rate', 'involvement'])]\n",
    "\n",
    "print(f\"\\n📋 Efficiency features created: {len(efficiency_features)}\")\n",
    "for feature in efficiency_features[:12]:  # Show first 12\n",
    "    print(f\"   • {feature}\")\n",
    "\n",
    "# Sample efficiency metrics for different positions\n",
    "positions = {1: 'GKP', 2: 'DEF', 3: 'MID', 4: 'FWD'}\n",
    "print(f\"\\n📈 Sample efficiency metrics by position:\")\n",
    "\n",
    "for pos_code, pos_name in positions.items():\n",
    "    pos_data = enhanced_df[enhanced_df['element_type'] == pos_code]\n",
    "    if len(pos_data) > 0:\n",
    "        sample = pos_data[pos_data['minutes'] > 0].iloc[0]\n",
    "        print(f\"\\n{pos_name} - {sample['web_name']}:\")\n",
    "        print(f\"   • Price Performance: {sample['price_performance_ratio']:.2f}\")\n",
    "        print(f\"   • Minutes per Point: {sample['minutes_per_point']:.1f}\")\n",
    "        if pos_code == 1 and 'gk_efficiency' in sample.index:\n",
    "            print(f\"   • GK Efficiency: {sample['gk_efficiency']:.2f}\")\n",
    "        elif pos_code == 2 and 'def_efficiency' in sample.index:\n",
    "            print(f\"   • DEF Efficiency: {sample['def_efficiency']:.2f}\")\n",
    "        elif pos_code == 3 and 'mid_efficiency' in sample.index:\n",
    "            print(f\"   • MID Efficiency: {sample['mid_efficiency']:.2f}\")\n",
    "        elif pos_code == 4 and 'fwd_efficiency' in sample.index:\n",
    "            print(f\"   • FWD Efficiency: {sample['fwd_efficiency']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543929b5",
   "metadata": {},
   "source": [
    "## 5. Contextual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e59f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Performing feature selection and validation...\n",
      "🎯 Analyzing features for predicting: total_points\n",
      "📊 Total features to analyze: 89\n",
      "📈 Features after variance filter: 82\n",
      "\n",
      "🏆 Top 15 most important features:\n",
      "    1. price_performance_ratio   - 1.7294\n",
      "    2. points_per_million        - 1.7148\n",
      "    3. points_form_3gw           - 1.3735\n",
      "    4. points_form_6gw           - 1.3731\n",
      "    5. points_form_4gw           - 1.3675\n",
      "    6. form_value_3gw            - 1.2141\n",
      "    7. minutes_per_point         - 1.0559\n",
      "    8. recent_vs_avg             - 0.9842\n",
      "    9. points_per_minute         - 0.8455\n",
      "   10. points_consistency        - 0.8393\n",
      "   11. points_momentum           - 0.7580\n",
      "   12. minutes                   - 0.6439\n",
      "   13. minutes_avg_3gw           - 0.6413\n",
      "   14. minutes_avg_4gw           - 0.6334\n",
      "   15. minutes_avg_6gw           - 0.6256\n",
      "\n",
      "🔬 Feature correlation analysis...\n",
      "📊 Features most correlated with total_points:\n",
      "    1. points_form_3gw           - +0.9891\n",
      "    2. points_form_6gw           - +0.9850\n",
      "    3. points_form_4gw           - +0.9850\n",
      "    4. price_performance_ratio   - +0.9704\n",
      "    5. points_per_million        - +0.9704\n",
      "    6. form_value_3gw            - +0.9591\n",
      "    7. points_consistency        - +0.9470\n",
      "    8. points_momentum           - +0.8926\n",
      "    9. minutes                   - +0.8564\n",
      "   10. minutes_avg_3gw           - +0.8503\n",
      "\n",
      "🎯 Position-specific feature analysis...\n",
      "🎯 Analyzing features for predicting: total_points\n",
      "📊 Total features to analyze: 89\n",
      "📈 Features after variance filter: 55\n",
      "\n",
      "🏆 Top 15 most important features:\n",
      "    1. points_per_million        - 1.4582\n",
      "    2. price_performance_ratio   - 1.4493\n",
      "    3. points_form_4gw           - 1.1665\n",
      "    4. points_form_6gw           - 1.1137\n",
      "    5. points_form_3gw           - 1.0914\n",
      "    6. form_value_3gw            - 1.0858\n",
      "    7. minutes_per_point         - 0.8690\n",
      "    8. minutes                   - 0.6527\n",
      "    9. recent_vs_avg             - 0.6417\n",
      "   10. gk_efficiency             - 0.6218\n",
      "   11. minutes_avg_6gw           - 0.6101\n",
      "   12. points_momentum           - 0.6005\n",
      "   13. points_consistency        - 0.5956\n",
      "   14. minutes_avg_3gw           - 0.5923\n",
      "   15. minutes_avg_4gw           - 0.5765\n",
      "\n",
      "GKP - Top 5 features:\n",
      "   1. points_per_million   - 1.4582\n",
      "   2. price_performance_ratio - 1.4493\n",
      "   3. points_form_4gw      - 1.1665\n",
      "   4. points_form_6gw      - 1.1137\n",
      "   5. points_form_3gw      - 1.0914\n",
      "🎯 Analyzing features for predicting: total_points\n",
      "📊 Total features to analyze: 89\n",
      "📈 Features after variance filter: 65\n",
      "\n",
      "🏆 Top 15 most important features:\n",
      "    1. price_performance_ratio   - 1.8237\n",
      "    2. points_per_million        - 1.7981\n",
      "    3. points_form_3gw           - 1.4702\n",
      "    4. points_form_6gw           - 1.4385\n",
      "    5. points_form_4gw           - 1.3928\n",
      "    6. form_value_3gw            - 1.3521\n",
      "    7. minutes_per_point         - 1.0314\n",
      "    8. points_consistency        - 0.9013\n",
      "    9. recent_vs_avg             - 0.8717\n",
      "   10. points_momentum           - 0.8232\n",
      "   11. minutes_avg_6gw           - 0.6745\n",
      "   12. minutes_avg_3gw           - 0.6646\n",
      "   13. minutes_avg_4gw           - 0.6400\n",
      "   14. minutes                   - 0.6111\n",
      "   15. form                      - 0.5416\n",
      "\n",
      "DEF - Top 5 features:\n",
      "   1. price_performance_ratio - 1.8237\n",
      "   2. points_per_million   - 1.7981\n",
      "   3. points_form_3gw      - 1.4702\n",
      "   4. points_form_6gw      - 1.4385\n",
      "   5. points_form_4gw      - 1.3928\n",
      "🎯 Analyzing features for predicting: total_points\n",
      "📊 Total features to analyze: 89\n",
      "📈 Features after variance filter: 66\n",
      "\n",
      "🏆 Top 15 most important features:\n",
      "    1. points_per_million        - 1.7733\n",
      "    2. price_performance_ratio   - 1.7527\n",
      "    3. points_form_3gw           - 1.4042\n",
      "    4. points_form_6gw           - 1.3468\n",
      "    5. points_form_4gw           - 1.3385\n",
      "    6. form_value_3gw            - 1.2137\n",
      "    7. minutes_per_point         - 0.9174\n",
      "    8. recent_vs_avg             - 0.8778\n",
      "    9. points_consistency        - 0.8119\n",
      "   10. points_momentum           - 0.7390\n",
      "   11. minutes                   - 0.6650\n",
      "   12. points_per_minute         - 0.6615\n",
      "   13. minutes_avg_3gw           - 0.6263\n",
      "   14. minutes_avg_6gw           - 0.6109\n",
      "   15. passes_per_90             - 0.5894\n",
      "\n",
      "MID - Top 5 features:\n",
      "   1. points_per_million   - 1.7733\n",
      "   2. price_performance_ratio - 1.7527\n",
      "   3. points_form_3gw      - 1.4042\n",
      "   4. points_form_6gw      - 1.3468\n",
      "   5. points_form_4gw      - 1.3385\n",
      "🎯 Analyzing features for predicting: total_points\n",
      "📊 Total features to analyze: 89\n",
      "📈 Features after variance filter: 68\n",
      "\n",
      "🏆 Top 15 most important features:\n",
      "    1. price_performance_ratio   - 1.4065\n",
      "    2. points_per_million        - 1.3983\n",
      "    3. points_form_6gw           - 1.2587\n",
      "    4. points_form_4gw           - 1.2560\n",
      "    5. points_form_3gw           - 1.2320\n",
      "    6. form_value_3gw            - 1.0768\n",
      "    7. points_consistency        - 0.8286\n",
      "    8. recent_vs_avg             - 0.7961\n",
      "    9. points_momentum           - 0.7921\n",
      "   10. minutes_per_point         - 0.7723\n",
      "   11. minutes_avg_4gw           - 0.6015\n",
      "   12. minutes_avg_6gw           - 0.5915\n",
      "   13. minutes                   - 0.5842\n",
      "   14. minutes_avg_3gw           - 0.5579\n",
      "   15. points_per_minute         - 0.5498\n",
      "\n",
      "FWD - Top 5 features:\n",
      "   1. price_performance_ratio - 1.4065\n",
      "   2. points_per_million   - 1.3983\n",
      "   3. points_form_6gw      - 1.2587\n",
      "   4. points_form_4gw      - 1.2560\n",
      "   5. points_form_3gw      - 1.2320\n",
      "\n",
      "📊 Feature engineering summary:\n",
      "✅ Original columns: 37\n",
      "✅ Enhanced columns: 94\n",
      "✅ New features created: 57\n",
      "\n",
      "📋 Feature categories created:\n",
      "   • Position-specific: 10 features\n",
      "   • Form indicators: 17 features\n",
      "   • Efficiency metrics: 26 features\n",
      "   • Value metrics: 3 features\n",
      "\n",
      "💾 Saving enhanced dataset...\n",
      "✅ Enhanced dataset saved to: data/enhanced_fpl_features.csv\n",
      "\n",
      "🎯 Ready for 2025/26 season modeling!\n",
      "📊 Dataset prepared with 2960 records and 94 features\n",
      "🚀 Next step: Build predictive models using these features\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection and Validation for 2025/26 Modeling\n",
    "print(\"🔍 Performing feature selection and validation...\")\n",
    "\n",
    "def analyze_feature_importance(df, target_col='total_points'):\n",
    "    \"\"\"\n",
    "    Analyze feature importance for predicting player performance\n",
    "    \"\"\"\n",
    "    print(f\"🎯 Analyzing features for predicting: {target_col}\")\n",
    "    \n",
    "    # Prepare data for feature selection\n",
    "    feature_df = df.copy()\n",
    "    \n",
    "    # Remove non-numeric and identifier columns\n",
    "    exclude_cols = ['web_name', 'team', 'player_id', 'gameweek']\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [col for col in numeric_cols if col not in exclude_cols and col != target_col]\n",
    "    \n",
    "    print(f\"📊 Total features to analyze: {len(feature_cols)}\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = feature_df[feature_cols].fillna(0)\n",
    "    y = feature_df[target_col].fillna(0)\n",
    "    \n",
    "    # Remove features with zero variance\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    variance_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_filtered = variance_selector.fit_transform(X)\n",
    "    selected_features = [feature_cols[i] for i in range(len(feature_cols)) if variance_selector.variances_[i] > 0.01]\n",
    "    \n",
    "    print(f\"📈 Features after variance filter: {len(selected_features)}\")\n",
    "    \n",
    "    # Feature importance using mutual information\n",
    "    from sklearn.feature_selection import mutual_info_regression\n",
    "    mi_scores = mutual_info_regression(X_filtered, y, random_state=42)\n",
    "    mi_results = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': mi_scores\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n🏆 Top 15 most important features:\")\n",
    "    for i, (_, row) in enumerate(mi_results.head(15).iterrows(), 1):\n",
    "        print(f\"   {i:2d}. {row['feature']:<25} - {row['importance']:.4f}\")\n",
    "    \n",
    "    return mi_results, selected_features, X_filtered, y\n",
    "\n",
    "# Analyze feature importance\n",
    "feature_importance, selected_features, X_processed, y_target = analyze_feature_importance(enhanced_df)\n",
    "\n",
    "print(f\"\\n🔬 Feature correlation analysis...\")\n",
    "\n",
    "# Analyze correlation between top features\n",
    "top_features = feature_importance.head(20)['feature'].tolist()\n",
    "correlation_matrix = enhanced_df[top_features + ['total_points']].corr()\n",
    "\n",
    "# Show highest correlations with target\n",
    "target_correlations = correlation_matrix['total_points'].drop('total_points').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(f\"📊 Features most correlated with total_points:\")\n",
    "for i, (feature, corr) in enumerate(target_correlations.head(10).items(), 1):\n",
    "    print(f\"   {i:2d}. {feature:<25} - {corr:+.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 Position-specific feature analysis...\")\n",
    "\n",
    "# Analyze feature importance by position\n",
    "positions = {1: 'GKP', 2: 'DEF', 3: 'MID', 4: 'FWD'}\n",
    "\n",
    "position_insights = {}\n",
    "for pos_code, pos_name in positions.items():\n",
    "    pos_data = enhanced_df[enhanced_df['element_type'] == pos_code]\n",
    "    if len(pos_data) > 50:  # Minimum sample size\n",
    "        pos_importance, _, _, _ = analyze_feature_importance(pos_data)\n",
    "        position_insights[pos_name] = pos_importance.head(5)\n",
    "        \n",
    "        print(f\"\\n{pos_name} - Top 5 features:\")\n",
    "        for i, (_, row) in enumerate(pos_importance.head(5).iterrows(), 1):\n",
    "            print(f\"   {i}. {row['feature']:<20} - {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 Feature engineering summary:\")\n",
    "print(f\"✅ Original columns: {len(players_df.columns)}\")\n",
    "print(f\"✅ Enhanced columns: {len(enhanced_df.columns)}\")\n",
    "print(f\"✅ New features created: {len(enhanced_df.columns) - len(players_df.columns)}\")\n",
    "\n",
    "# Feature categories summary\n",
    "categories = {\n",
    "    'Position-specific': [col for col in enhanced_df.columns if any(keyword in col for keyword in \n",
    "                         ['gk_', 'def_', 'mid_', 'fwd_', 'save_', 'defensive_actions', 'creativity_', 'shot_conversion'])],\n",
    "    'Form indicators': [col for col in enhanced_df.columns if any(keyword in col for keyword in \n",
    "                       ['form', 'momentum', 'consistency'])],\n",
    "    'Efficiency metrics': [col for col in enhanced_df.columns if any(keyword in col for keyword in \n",
    "                          ['per_90', 'efficiency', 'rate', 'accuracy', 'ratio'])],\n",
    "    'Value metrics': [col for col in enhanced_df.columns if any(keyword in col for keyword in \n",
    "                     ['per_million', 'value', 'price_performance'])]\n",
    "}\n",
    "\n",
    "print(f\"\\n📋 Feature categories created:\")\n",
    "for category, features in categories.items():\n",
    "    print(f\"   • {category}: {len(features)} features\")\n",
    "\n",
    "print(f\"\\n💾 Saving enhanced dataset...\")\n",
    "\n",
    "# Save the enhanced dataset for modeling\n",
    "enhanced_df.to_csv('../../data/enhanced_fpl_features.csv', index=False)\n",
    "print(f\"✅ Enhanced dataset saved to: data/enhanced_fpl_features.csv\")\n",
    "\n",
    "print(f\"\\n🎯 Ready for 2025/26 season modeling!\")\n",
    "print(f\"📊 Dataset prepared with {len(enhanced_df)} records and {len(enhanced_df.columns)} features\")\n",
    "print(f\"🚀 Next step: Build predictive models using these features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800811c3",
   "metadata": {},
   "source": [
    "## 6. Feature Selection and Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d01aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(X, y, method='mutual_info', k=20):\n",
    "    \"\"\"\n",
    "    Select most important features for prediction\n",
    "    \"\"\"\n",
    "    if method == 'mutual_info':\n",
    "        selector = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    \n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    feature_scores = selector.scores_[selector.get_support()]\n",
    "    \n",
    "    return X_selected, selected_features, feature_scores\n",
    "\n",
    "def plot_feature_importance(features, scores, title=\"Feature Importance\"):\n",
    "    \"\"\"\n",
    "    Plot feature importance scores\n",
    "    \"\"\"\n",
    "    feature_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': scores\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(feature_df['feature'], feature_df['importance'])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "# TODO: Apply feature selection\n",
    "# numeric_features = player_data.select_dtypes(include=[np.number]).columns\n",
    "# X = player_data[numeric_features].fillna(0)\n",
    "# y = player_data['next_match_rating']  # Target variable\n",
    "# \n",
    "# X_selected, selected_features, scores = select_important_features(X, y)\n",
    "# feature_importance_df = plot_feature_importance(selected_features, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
